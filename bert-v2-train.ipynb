{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90ae68e1-21c5-4951-9022-05be8a3d5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForPreTraining\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import TextDatasetForNextSentencePrediction\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac0f195b-b280-4ec5-9b48-fc13adfbf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_base = Path('./polished/models/ka_only_no_w2v_bert/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdbdf376-b12b-40e6-8af4-56cca3903ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './no_en_data/ka_nse_train.txt'\n",
    "test_file = './no_en_data/ka_nse_test.txt'\n",
    "valid_file = './no_en_data/ka_nse_valid.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5a511-19bb-4c9d-a543-5622247d3dbc",
   "metadata": {},
   "source": [
    "### Central config for useful hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9868b33-ff51-4bfd-804e-335d7d4f445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GeoBertConfig:\n",
    "    do_lower_case: bool\n",
    "    do_basic_tokenize: bool\n",
    "    tokenize_chinese_chars: bool\n",
    "    word_embedding_size: int\n",
    "    num_transformer_layers: int\n",
    "    num_heads: int\n",
    "    hidden_feed_forward_size: int\n",
    "    mlm_probability: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddd1910-4567-4c2b-b00d-fda3af4b714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GeoBertConfig(\n",
    "    do_lower_case=False, # georgian doesn't have lower case\n",
    "    do_basic_tokenize=True, # doesn't really matter, basic tokenizetion speeds up stuff\n",
    "    tokenize_chinese_chars=False, # we don't care about chinese chars\n",
    "    word_embedding_size=300, # same as w2v embeddings\n",
    "    num_transformer_layers=12,\n",
    "    num_heads=12,\n",
    "    hidden_feed_forward_size=1024,\n",
    "    mlm_probability=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66e7d3-3982-4283-83b7-d67871152891",
   "metadata": {},
   "source": [
    "### Open already trained BertTokenizer which is now aware of special token meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a00dbba5-0e71-448d-a1e3-3bad0a1d952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./polished/models/v2bert/berttokenizer/added_tokens.json. We won't load it.\n",
      "loading file ./polished/models/v2bert/berttokenizer/vocab.txt\n",
      "loading file None\n",
      "loading file ./polished/models/v2bert/berttokenizer/special_tokens_map.json\n",
      "loading file ./polished/models/v2bert/berttokenizer/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./polished/models/v2bert/berttokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7143e30c-8334-498c-ae50-68d6d4396ac0",
   "metadata": {},
   "source": [
    "### Load up dataset for NSE task\n",
    "* Data file format:\n",
    "\n",
    "```txt\n",
    "sentence-1 from document-1\\n\n",
    "sentence-2 from document-1\\n\n",
    "sentence-3 from document-1\\n\n",
    "\\n\n",
    "sentence-1 from document-2\\n\n",
    "sentence-2 from document-2\\n\n",
    "...\n",
    "```\n",
    "* `TextDatasetForNextSentencePrediction` does pairing of sentences for NSE task for us\n",
    "    * 50% of times it will pair random chunks of text\n",
    "    * 50% of times pair will be contigius in underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e52db2-5bef-4236-a430-bc45f555ce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/geolm/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:362: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDatasetForNextSentencePrediction(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=str(train_file),\n",
    "    block_size = 256, # max sentence len. 512 because georgian is pretty long compared to others\n",
    ")\n",
    "test_dataset = TextDatasetForNextSentencePrediction(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=str(test_file),\n",
    "    block_size = 256, # max sentence len. 512 because georgian is pretty long compared to others\n",
    ")\n",
    "valid_dataset = TextDatasetForNextSentencePrediction(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=str(valid_file),\n",
    "    block_size = 256, # max sentence len. 512 because georgian is pretty long compared to others\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceafd7de-35e6-4a57-8c2b-599842078b74",
   "metadata": {},
   "source": [
    "### Filter out all sentences with len >= 300 so cuda does not run into OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5205e18a-020f-497e-9056-eaab3300981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.examples = [ex for ex in train_dataset.examples if len(ex['input_ids']) < 300]\n",
    "test_dataset.examples = [ex for ex in test_dataset.examples if len(ex['input_ids']) < 300][:100] # for quick eval prints\n",
    "valid_dataset.examples = [ex for ex in valid_dataset.examples if len(ex['input_ids']) < 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0a722-6c3c-4a5e-95c6-34e838b025d6",
   "metadata": {},
   "source": [
    "* `input_ids` - input token ids\n",
    "* `token_type_ids` - which sequence does each token belong to\n",
    "* `next_sentence_label` - NSE task expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "797f7a21-6847-4fc7-995c-466bbe6bb09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132598, 100, 19241)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95c1c00d-eb01-4a2e-baea-866bd874c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] áƒ’áƒáƒ“áƒ›áƒáƒ’áƒ˜áƒ¨áƒšáƒ˜ áƒ›áƒ—áƒ”áƒš áƒ©áƒ”áƒ›áƒ¡ áƒªáƒ®áƒáƒ•áƒ áƒ”áƒ‘áƒáƒ¡, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒœáƒáƒ›áƒ“áƒ•áƒ˜áƒšáƒáƒ“ áƒ›áƒáƒ¨áƒ˜áƒœ áƒ“áƒáƒ˜áƒ¬áƒ§áƒ, áƒ áƒáƒ“áƒ”áƒ¡áƒáƒª áƒžáƒ˜áƒ áƒ•áƒ”áƒšáƒáƒ“ áƒ’áƒ˜áƒ®áƒ˜áƒšáƒ”. áƒ›áƒáƒœáƒáƒ›áƒ“áƒ” áƒ©áƒ”áƒ›áƒ—áƒ•áƒ˜áƒ¡ áƒáƒ áƒ¡áƒ”áƒ‘áƒáƒ‘áƒ“áƒ áƒ›áƒ®áƒáƒšáƒáƒ“ áƒ áƒáƒ¦áƒáƒª áƒ‘áƒ£áƒœáƒ“áƒáƒ•áƒáƒœáƒ˜, áƒ’áƒáƒ£áƒ áƒ™áƒ•áƒ”áƒ•áƒ”áƒšáƒ˜ áƒ¡áƒáƒ›áƒ§áƒáƒ áƒ, áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’ áƒáƒ˜áƒœáƒ£áƒœáƒ¨áƒ˜áƒáƒª áƒ áƒáƒ› áƒáƒ¦áƒáƒ  áƒ›áƒáƒ›áƒ¡áƒ•áƒšáƒ˜áƒ, áƒ áƒáƒ¦áƒáƒª áƒ‘áƒœáƒ”áƒšáƒ˜ áƒ¯áƒ£áƒ áƒ¦áƒ›áƒ£áƒšáƒ˜, áƒáƒ‘áƒšáƒáƒ‘áƒ£áƒ“áƒ˜áƒ—áƒ áƒ“áƒ áƒ›áƒ¢áƒ•áƒ”áƒ áƒ˜áƒ— áƒ“áƒáƒ¤áƒáƒ áƒ£áƒšáƒ˜ áƒ¡áƒáƒ’áƒœáƒ”áƒ‘áƒ˜ áƒ“áƒ áƒ®áƒáƒšáƒ®áƒ˜, áƒ áƒáƒ›áƒ”áƒšáƒ—áƒ áƒ¨áƒ”áƒ¡áƒáƒ®áƒ”áƒ‘ áƒ©áƒ”áƒ›áƒ›áƒ áƒ›áƒ”áƒ®áƒ¡áƒ˜áƒ”áƒ áƒ”áƒ‘áƒáƒ› áƒ—áƒ˜áƒ—áƒ¥áƒ›áƒ˜áƒ¡ áƒáƒ¦áƒáƒ áƒáƒ¤áƒ áƒ˜ áƒ¨áƒ”áƒ›áƒáƒ˜áƒœáƒáƒ®áƒ. áƒ¨áƒ”áƒœ áƒ áƒáƒ› áƒ’áƒáƒ›áƒáƒ©áƒœáƒ“áƒ˜, áƒªáƒáƒ›áƒ”áƒ¢áƒ˜ áƒ¬áƒšáƒ˜áƒ¡áƒ áƒ•áƒ˜áƒ§áƒáƒ•áƒ˜, áƒ•áƒªáƒ®áƒáƒ•áƒ áƒáƒ‘áƒ“áƒ˜ áƒ˜áƒ›áƒáƒ•áƒ” áƒ¡áƒáƒ®áƒšáƒ¨áƒ˜, áƒ¡áƒáƒ“áƒáƒª áƒáƒ®áƒšáƒ áƒªáƒ®áƒáƒ•áƒ áƒáƒ‘, áƒ¡áƒ¬áƒáƒ áƒ”áƒ“ áƒ˜áƒ› áƒ¡áƒáƒ®áƒšáƒ¨áƒ˜, áƒ¡áƒáƒ“áƒáƒª áƒáƒ®áƒšáƒ áƒ–áƒ˜áƒ®áƒáƒ  áƒ“áƒ áƒ®áƒ”áƒšáƒ— áƒ’áƒ˜áƒ­áƒ˜áƒ áƒáƒ•áƒ¡ áƒ”áƒ¡ áƒ¬áƒ”áƒ áƒ˜áƒšáƒ˜ â€“ áƒ©áƒ”áƒ›áƒ˜ áƒªáƒ®áƒáƒ•áƒ áƒ”áƒ‘áƒ˜áƒ¡ áƒ£áƒ™áƒáƒœáƒáƒ¡áƒ™áƒœáƒ”áƒšáƒ˜ áƒáƒ›áƒáƒ¡áƒ£áƒœáƒ—áƒ¥áƒ•áƒ ; áƒ•áƒªáƒ®áƒáƒ•áƒ áƒáƒ‘áƒ“áƒ˜ áƒ˜áƒ›áƒáƒ•áƒ” áƒ¡áƒáƒ áƒ—áƒ£áƒšáƒ–áƒ”, áƒ¨áƒ”áƒœáƒ˜ áƒ™áƒáƒ áƒ˜áƒ¡ áƒ›áƒ”áƒ–áƒáƒ‘áƒ”áƒšáƒ˜ áƒ•áƒ˜áƒ§áƒáƒ•áƒ˜. áƒáƒ‘áƒ, áƒ áƒáƒ¦áƒáƒ¡ áƒ’áƒ”áƒ®áƒ¡áƒáƒ›áƒ”áƒ‘áƒ˜áƒ— â€“ áƒ¤áƒ˜áƒœáƒáƒœáƒ¡áƒ£áƒ  áƒ¡áƒáƒ¥áƒ›áƒ”áƒ—áƒ áƒ›áƒ áƒ©áƒ”áƒ•áƒšáƒ˜áƒ¡ áƒ¦áƒáƒ¢áƒáƒ™áƒ˜ áƒ¥áƒ•áƒ áƒ˜áƒ•áƒ˜ ( áƒ§áƒáƒ•áƒ”áƒšáƒ—áƒ•áƒ˜áƒ¡ áƒ«áƒáƒ«áƒ áƒ”áƒªáƒ•áƒ ) áƒ“áƒ áƒáƒ“áƒœáƒáƒ• áƒ›áƒáƒ©áƒ˜áƒ¢áƒ£áƒšáƒ˜ áƒ’áƒáƒ›áƒ®áƒ“áƒáƒ áƒ˜ áƒ’áƒáƒ’áƒáƒœáƒ. [SEP] áƒ¥áƒ£áƒ—áƒáƒ˜áƒ¡áƒ˜áƒ¡ áƒ›áƒ”áƒ áƒ˜áƒ˜áƒ¡ áƒ’áƒáƒœáƒ›áƒáƒ áƒ¢áƒ”áƒ‘áƒ˜áƒ—, áƒ›áƒáƒ— áƒ£áƒ™áƒ•áƒ” áƒ›áƒáƒ˜áƒšáƒáƒžáƒáƒ áƒáƒ™áƒ”áƒ¡ áƒ‘áƒáƒ–áƒ áƒáƒ‘áƒ”áƒ‘áƒ˜áƒ¡ áƒ®áƒ”áƒšáƒ›áƒ«áƒ¦áƒ•áƒáƒœáƒ”áƒšáƒ”áƒ‘áƒ—áƒáƒœ, áƒ áƒáƒ›áƒšáƒ”áƒ‘áƒ˜áƒª áƒ›áƒ–áƒáƒ“ áƒáƒ áƒ˜áƒáƒœ áƒ’áƒáƒ áƒ”áƒ›áƒáƒ•áƒáƒ­áƒ áƒ”áƒ”áƒ‘áƒ¡ áƒ¡áƒáƒ›áƒ˜ áƒ—áƒ•áƒ˜áƒ— áƒ£áƒ¤áƒáƒ¡áƒáƒ“ áƒ’áƒáƒ›áƒáƒ£áƒ§áƒáƒœ áƒ“áƒáƒ®áƒšáƒ”áƒ‘áƒ˜. áƒ›áƒáƒ•áƒáƒ­áƒ áƒ”áƒ”áƒ‘áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ áƒ›áƒ”áƒ áƒ˜áƒ˜áƒ¡ áƒ›áƒ˜áƒ”áƒ  áƒ¨áƒ”áƒ—áƒáƒ•áƒáƒ–áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒžáƒ˜áƒ áƒáƒ‘áƒ”áƒ‘áƒ˜ áƒ›áƒ˜áƒ£áƒ¦áƒ”áƒ‘áƒ”áƒšáƒ˜ áƒáƒ¦áƒ›áƒáƒ©áƒœáƒ“áƒ. [SEP]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_dataset[100]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "643ad4d6-fd21-4767-a847-4d4da5449ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.vocab_size = 30000, len(train_dataset) = 132598\n"
     ]
    }
   ],
   "source": [
    "print(f'{tokenizer.vocab_size = }, {len(train_dataset) = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a78e6670-48e1-4eea-89d4-946c37e6b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "hug_config = BertConfig(tokenizer.vocab_size, \n",
    "                    hidden_size=config.word_embedding_size,\n",
    "                    num_hidden_layers=config.num_transformer_layers, \n",
    "                    num_attention_heads=config.num_heads,\n",
    "                    intermediate_size=config.hidden_feed_forward_size)\n",
    "model = BertForPreTraining(hug_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7eeeca-bd5b-4f2a-a50b-177f86cdef9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load up w2v embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36505c59-31cf-4969-82c0-ca0b8b96e9f4",
   "metadata": {},
   "source": [
    "DO NOT RUN THIS TO GET MODEL WITHOUT W2V EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b7566-0b44-4cc4-858f-50078bc8f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74087d05-a5e8-4169-968a-3bcefc25f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('./polished/models/word2vec/subword.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "743bef68-d550-43f5-b941-871064afdb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing = model.bert.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05eb5dc9-7b7e-4948-9bd2-ad46b9d8cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = torch.zeros((tokenizer.vocab_size, config.word_embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b077d3c0-c420-49da-813e-6aa693e06e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, i in tokenizer.get_vo6648cab().items():\n",
    "    if k in wvmodel.wv:\n",
    "        pretrained_embeddings[i] = torch.tensor(wvmodel.wv[k])\n",
    "    else:\n",
    "        pretrained_embeddings[i] = existing[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed40505-dd98-4c9b-840d-db66062f1b43",
   "metadata": {},
   "source": [
    "Check in vocab word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2de87e5-76d1-4b57-ba3c-a824b2e9c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(pretrained_embeddings[tokenizer.get_vocab()['áƒ']] == torch.tensor(wvmodel.wv['áƒ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a15d2b-a0bc-45f6-b8a2-c51b4f586ca5",
   "metadata": {},
   "source": [
    "Check out of vocab word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0092a12-ea7a-49e0-bf3e-96d4cfc1c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(pretrained_embeddings[1] == existing[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bc11c-0bb5-4e85-be5a-27b614efbea0",
   "metadata": {},
   "source": [
    "### Actually replace embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3099e703-a3a6-4dd0-9fb8-1f6c799018a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bert.embeddings.word_embeddings = nn.Embedding.from_pretrained(embeddings=pretrained_embeddings, \n",
    "                                                                     freeze = False, # We want model to learn [SEP] embeddings for example\n",
    "                                                                     padding_idx=0,\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a8e39-6163-42c0-8ea6-77ea40300ea0",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a719f-4cf5-43b0-82d6-40a32a3573f3",
   "metadata": {},
   "source": [
    "### Set up mlm collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "358eca7c-f5b0-4544-b31b-5779af32f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=config.mlm_probability,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e549da0-7d89-4bf7-8a6c-2964779aec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4702d7-6c57-446a-a69d-d860b9443f56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/anaconda/envs/geolm/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 132598\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 12\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 110500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6992' max='110500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6992/110500 1:02:37 < 15:27:18, 1.86 it/s, Epoch 0.63/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.238300</td>\n",
       "      <td>9.642043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.501200</td>\n",
       "      <td>9.133760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>9.131600</td>\n",
       "      <td>8.999308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.976600</td>\n",
       "      <td>8.918166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.938900</td>\n",
       "      <td>8.667453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.896100</td>\n",
       "      <td>8.785086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>8.811600</td>\n",
       "      <td>8.813850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.820800</td>\n",
       "      <td>8.684848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>8.786700</td>\n",
       "      <td>8.553764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.751300</td>\n",
       "      <td>8.638752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>8.683200</td>\n",
       "      <td>8.666167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>8.698100</td>\n",
       "      <td>8.611069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>8.674300</td>\n",
       "      <td>8.556291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>8.689800</td>\n",
       "      <td>8.501641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>8.617100</td>\n",
       "      <td>8.608245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>8.637000</td>\n",
       "      <td>8.427113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>8.631900</td>\n",
       "      <td>8.510557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>8.580300</td>\n",
       "      <td>8.441566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>8.563900</td>\n",
       "      <td>8.453546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.574100</td>\n",
       "      <td>8.366509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>8.527900</td>\n",
       "      <td>8.518157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>8.531800</td>\n",
       "      <td>8.405278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>8.487600</td>\n",
       "      <td>8.361155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>8.521300</td>\n",
       "      <td>8.305776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>8.468800</td>\n",
       "      <td>8.373627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>8.470500</td>\n",
       "      <td>8.420248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>8.455000</td>\n",
       "      <td>8.219448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>8.428300</td>\n",
       "      <td>8.367229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>8.452700</td>\n",
       "      <td>8.347764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>8.448800</td>\n",
       "      <td>8.213326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>8.478000</td>\n",
       "      <td>8.177825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>8.454300</td>\n",
       "      <td>8.281873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>8.459000</td>\n",
       "      <td>8.390621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>8.467900</td>\n",
       "      <td>8.416553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>8.407200</td>\n",
       "      <td>8.339363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>8.373600</td>\n",
       "      <td>8.287086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>8.379900</td>\n",
       "      <td>8.232206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>8.388700</td>\n",
       "      <td>8.238578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>8.366200</td>\n",
       "      <td>8.103189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>8.353800</td>\n",
       "      <td>8.201151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>8.349100</td>\n",
       "      <td>8.203523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>8.355000</td>\n",
       "      <td>8.231941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>8.381000</td>\n",
       "      <td>8.214046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>8.376100</td>\n",
       "      <td>8.097723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>8.310600</td>\n",
       "      <td>8.212900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>8.296100</td>\n",
       "      <td>8.109522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>8.266400</td>\n",
       "      <td>8.204401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>8.338000</td>\n",
       "      <td>8.075732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>8.313500</td>\n",
       "      <td>8.220948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>8.328300</td>\n",
       "      <td>8.056803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>8.268000</td>\n",
       "      <td>8.108474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>8.306500</td>\n",
       "      <td>8.050469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>8.281200</td>\n",
       "      <td>7.984207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>8.257900</td>\n",
       "      <td>7.930099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>8.262000</td>\n",
       "      <td>7.853549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>8.241400</td>\n",
       "      <td>7.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>8.219000</td>\n",
       "      <td>8.053595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>8.199300</td>\n",
       "      <td>7.950341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>8.208900</td>\n",
       "      <td>7.862159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>8.262600</td>\n",
       "      <td>7.974393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>8.180100</td>\n",
       "      <td>7.950816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>8.269000</td>\n",
       "      <td>8.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>8.157400</td>\n",
       "      <td>7.988266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>8.165200</td>\n",
       "      <td>8.074214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>8.173800</td>\n",
       "      <td>8.009265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>8.162000</td>\n",
       "      <td>8.047486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>8.169100</td>\n",
       "      <td>8.022649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>8.199700</td>\n",
       "      <td>7.976508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>8.153000</td>\n",
       "      <td>8.046255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-1000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-1000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-2000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-2000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-3000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-3000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [polished/models/ka_only_no_w2v_bert/trainer/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-4000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-4000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [polished/models/ka_only_no_w2v_bert/trainer/checkpoint-2000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-5000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-5000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [polished/models/ka_only_no_w2v_bert/trainer/checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Bad pipe message: %s [b'buO[\\x9f\\x02\\xb0\\x81h\\xed\\x98O\\xe8i\\x86W\\x7fW\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]', b\"\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\", b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b\"\\xa9G\\x91 \\x96M>\\xef\\x1d\\xa2\\xc4F\\x82ORm\\x82\\xe9\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x00\", b'\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/']\n",
      "Bad pipe message: %s [b'q\\xbf\\xe9\\x8aJk\\x082\\x1f\\x02\\xd6~3\\xd2B$\\x92\\x84\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'10D\\xdd\\xd4\\x89\\xbe\\x96\\x0c@]\\x8c\\xd4\\x0e\\xee\\xc7\\xaf\\xdf\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04']\n",
      "Bad pipe message: %s [b'\\x01\\x02']\n",
      "Bad pipe message: %s [b'\\x08dj0\\xe6', b'\\xf0T\\xe2\\xc5(|\\xb2\\xdc:HU\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n']\n",
      "Bad pipe message: %s [b';?\\x0c\\xa0\\x8f\\x17\\x1bs\\x13\\xfc\\xbd\\xe1\\x0f\\x82\\xe4\\x1c%\\x02\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0', b'\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16']\n",
      "Bad pipe message: %s [b\"\\xd9\\x91\\xa9O\\x8bXh\\xc2\\x19\\t`_\\xf3\\xbbN\\xf7\\xb6\\xfb\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\"]\n",
      "Bad pipe message: %s [b\"\\x9c\\xf2\\x96\\x84\\xa8\\x83\\xaf\\xd9aa\\xcb\\x1a\\x9f\\xafTX/`\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\"]\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-6000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-6000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [polished/models/ka_only_no_w2v_bert/trainer/checkpoint-4000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=12,\n",
    "    \n",
    "    #prediction_loss_only=True,\n",
    "    evaluation_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_accumulation_steps=1,\n",
    "    #eval_steps=2000,\n",
    "    logging_first_step=True,\n",
    "    \n",
    "    output_dir= str(out_base/ 'trainer'),\n",
    "    # overwrite_output_dir=True,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6579af3-d39f-4531-99e0-7245b093ffe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/ka_only_no_w2v_bert_model\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/ka_only_no_w2v_bert_model/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/ka_only_no_w2v_bert_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(str(out_base / 'ka_only_no_w2v_bert_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3fc3109-94da-4179-9439-c93ff5c3a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afe0d49e-9cff-4e3f-9f6a-546bcbe8dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert torch.all(model.bert.embeddings.word_embeddings.weight[tokenizer.get_vocab()['áƒ']] == torch.tensor(wvmodel.wv['áƒ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311654b-d757-424e-b99a-ae58ecc7687e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
