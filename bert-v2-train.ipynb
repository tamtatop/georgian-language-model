{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90ae68e1-21c5-4951-9022-05be8a3d5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForPreTraining\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import TextDatasetForNextSentencePrediction\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac0f195b-b280-4ec5-9b48-fc13adfbf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_base = Path('./polished/models/ka_only_no_w2v_bert/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdbdf376-b12b-40e6-8af4-56cca3903ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './no_en_data/ka_nse_train.txt'\n",
    "test_file = './no_en_data/ka_nse_test.txt'\n",
    "valid_file = './no_en_data/ka_nse_valid.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5a511-19bb-4c9d-a543-5622247d3dbc",
   "metadata": {},
   "source": [
    "### Central config for useful hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9868b33-ff51-4bfd-804e-335d7d4f445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GeoBertConfig:\n",
    "    do_lower_case: bool\n",
    "    do_basic_tokenize: bool\n",
    "    tokenize_chinese_chars: bool\n",
    "    word_embedding_size: int\n",
    "    num_transformer_layers: int\n",
    "    num_heads: int\n",
    "    hidden_feed_forward_size: int\n",
    "    mlm_probability: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddd1910-4567-4c2b-b00d-fda3af4b714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GeoBertConfig(\n",
    "    do_lower_case=False, # georgian doesn't have lower case\n",
    "    do_basic_tokenize=True, # doesn't really matter, basic tokenizetion speeds up stuff\n",
    "    tokenize_chinese_chars=False, # we don't care about chinese chars\n",
    "    word_embedding_size=300, # same as w2v embeddings\n",
    "    num_transformer_layers=12,\n",
    "    num_heads=12,\n",
    "    hidden_feed_forward_size=1024,\n",
    "    mlm_probability=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66e7d3-3982-4283-83b7-d67871152891",
   "metadata": {},
   "source": [
    "### Open already trained BertTokenizer which is now aware of special token meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a00dbba5-0e71-448d-a1e3-3bad0a1d952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./polished/models/v2bert/berttokenizer/added_tokens.json. We won't load it.\n",
      "loading file ./polished/models/v2bert/berttokenizer/vocab.txt\n",
      "loading file None\n",
      "loading file ./polished/models/v2bert/berttokenizer/special_tokens_map.json\n",
      "loading file ./polished/models/v2bert/berttokenizer/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./polished/models/v2bert/berttokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7143e30c-8334-498c-ae50-68d6d4396ac0",
   "metadata": {},
   "source": [
    "### Load up dataset for NSE task\n",
    "* Data file format:\n",
    "\n",
    "```txt\n",
    "sentence-1 from document-1\\n\n",
    "sentence-2 from document-1\\n\n",
    "sentence-3 from document-1\\n\n",
    "\\n\n",
    "sentence-1 from document-2\\n\n",
    "sentence-2 from document-2\\n\n",
    "...\n",
    "```\n",
    "* `TextDatasetForNextSentencePrediction` does pairing of sentences for NSE task for us\n",
    "    * 50% of times it will pair random chunks of text\n",
    "    * 50% of times pair will be contigius in underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e52db2-5bef-4236-a430-bc45f555ce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/geolm/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:362: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDatasetForNextSentencePrediction(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=str(train_file),\n",
    "    block_size = 256, # max sentence len. 512 because georgian is pretty long compared to others\n",
    ")\n",
    "test_dataset = TextDatasetForNextSentencePrediction(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=str(test_file),\n",
    "    block_size = 256, # max sentence len. 512 because georgian is pretty long compared to others\n",
    ")\n",
    "valid_dataset = TextDatasetForNextSentencePrediction(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=str(valid_file),\n",
    "    block_size = 256, # max sentence len. 512 because georgian is pretty long compared to others\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceafd7de-35e6-4a57-8c2b-599842078b74",
   "metadata": {},
   "source": [
    "### Filter out all sentences with len >= 300 so cuda does not run into OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5205e18a-020f-497e-9056-eaab3300981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.examples = [ex for ex in train_dataset.examples if len(ex['input_ids']) < 300]\n",
    "test_dataset.examples = [ex for ex in test_dataset.examples if len(ex['input_ids']) < 300][:100] # for quick eval prints\n",
    "valid_dataset.examples = [ex for ex in valid_dataset.examples if len(ex['input_ids']) < 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0a722-6c3c-4a5e-95c6-34e838b025d6",
   "metadata": {},
   "source": [
    "* `input_ids` - input token ids\n",
    "* `token_type_ids` - which sequence does each token belong to\n",
    "* `next_sentence_label` - NSE task expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "797f7a21-6847-4fc7-995c-466bbe6bb09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132598, 100, 19241)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95c1c00d-eb01-4a2e-baea-866bd874c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] გადმოგიშლი მთელ ჩემს ცხოვრებას, რომელიც ნამდვილად მაშინ დაიწყო, როდესაც პირველად გიხილე. მანამდე ჩემთვის არსებობდა მხოლოდ რაღაც ბუნდოვანი, გაურკვეველი სამყარო, შემდეგ აინუნშიაც რომ აღარ მომსვლია, რაღაც ბნელი ჯურღმული, აბლაბუდითა და მტვერით დაფარული საგნები და ხალხი, რომელთა შესახებ ჩემმა მეხსიერებამ თითქმის აღარაფრი შემოინახა. შენ რომ გამოჩნდი, ცამეტი წლისა ვიყავი, ვცხოვრობდი იმავე სახლში, სადაც ახლა ცხოვრობ, სწორედ იმ სახლში, სადაც ახლა ზიხარ და ხელთ გიჭირავს ეს წერილი – ჩემი ცხოვრების უკანასკნელი ამოსუნთქვა ; ვცხოვრობდი იმავე სართულზე, შენი კარის მეზობელი ვიყავი. აბა, რაღას გეხსომებით – ფინანსურ საქმეთა მრჩევლის ღატაკი ქვრივი ( ყოველთვის ძაძა ეცვა ) და ოდნავ მოჩიტული გამხდარი გოგონა. [SEP] ქუთაისის მერიის განმარტებით, მათ უკვე მოილაპარაკეს ბაზრობების ხელმძღვანელებთან, რომლებიც მზად არიან გარემოვაჭრეებს სამი თვით უფასოდ გამოუყონ დახლები. მოვაჭრეებისთვის მერიის მიერ შეთავაზებული პირობები მიუღებელი აღმოჩნდა. [SEP]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_dataset[100]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "643ad4d6-fd21-4767-a847-4d4da5449ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.vocab_size = 30000, len(train_dataset) = 132598\n"
     ]
    }
   ],
   "source": [
    "print(f'{tokenizer.vocab_size = }, {len(train_dataset) = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a78e6670-48e1-4eea-89d4-946c37e6b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "hug_config = BertConfig(tokenizer.vocab_size, \n",
    "                    hidden_size=config.word_embedding_size,\n",
    "                    num_hidden_layers=config.num_transformer_layers, \n",
    "                    num_attention_heads=config.num_heads,\n",
    "                    intermediate_size=config.hidden_feed_forward_size)\n",
    "model = BertForPreTraining(hug_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7eeeca-bd5b-4f2a-a50b-177f86cdef9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load up w2v embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36505c59-31cf-4969-82c0-ca0b8b96e9f4",
   "metadata": {},
   "source": [
    "DO NOT RUN THIS TO GET MODEL WITHOUT W2V EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b7566-0b44-4cc4-858f-50078bc8f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74087d05-a5e8-4169-968a-3bcefc25f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('./polished/models/word2vec/subword.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "743bef68-d550-43f5-b941-871064afdb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing = model.bert.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05eb5dc9-7b7e-4948-9bd2-ad46b9d8cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = torch.zeros((tokenizer.vocab_size, config.word_embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b077d3c0-c420-49da-813e-6aa693e06e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, i in tokenizer.get_vo6648cab().items():\n",
    "    if k in wvmodel.wv:\n",
    "        pretrained_embeddings[i] = torch.tensor(wvmodel.wv[k])\n",
    "    else:\n",
    "        pretrained_embeddings[i] = existing[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed40505-dd98-4c9b-840d-db66062f1b43",
   "metadata": {},
   "source": [
    "Check in vocab word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2de87e5-76d1-4b57-ba3c-a824b2e9c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(pretrained_embeddings[tokenizer.get_vocab()['ა']] == torch.tensor(wvmodel.wv['ა']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a15d2b-a0bc-45f6-b8a2-c51b4f586ca5",
   "metadata": {},
   "source": [
    "Check out of vocab word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0092a12-ea7a-49e0-bf3e-96d4cfc1c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(pretrained_embeddings[1] == existing[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bc11c-0bb5-4e85-be5a-27b614efbea0",
   "metadata": {},
   "source": [
    "### Actually replace embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3099e703-a3a6-4dd0-9fb8-1f6c799018a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bert.embeddings.word_embeddings = nn.Embedding.from_pretrained(embeddings=pretrained_embeddings, \n",
    "                                                                     freeze = False, # We want model to learn [SEP] embeddings for example\n",
    "                                                                     padding_idx=0,\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a8e39-6163-42c0-8ea6-77ea40300ea0",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a719f-4cf5-43b0-82d6-40a32a3573f3",
   "metadata": {},
   "source": [
    "### Set up mlm collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "358eca7c-f5b0-4544-b31b-5779af32f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=config.mlm_probability,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e549da0-7d89-4bf7-8a6c-2964779aec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4702d7-6c57-446a-a69d-d860b9443f56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/anaconda/envs/geolm/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 132598\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 12\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 110500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6992' max='110500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  6992/110500 1:02:37 < 15:27:18, 1.86 it/s, Epoch 0.63/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.238300</td>\n",
       "      <td>9.642043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.501200</td>\n",
       "      <td>9.133760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>9.131600</td>\n",
       "      <td>8.999308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.976600</td>\n",
       "      <td>8.918166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.938900</td>\n",
       "      <td>8.667453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.896100</td>\n",
       "      <td>8.785086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>8.811600</td>\n",
       "      <td>8.813850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.820800</td>\n",
       "      <td>8.684848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>8.786700</td>\n",
       "      <td>8.553764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.751300</td>\n",
       "      <td>8.638752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>8.683200</td>\n",
       "      <td>8.666167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>8.698100</td>\n",
       "      <td>8.611069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>8.674300</td>\n",
       "      <td>8.556291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>8.689800</td>\n",
       "      <td>8.501641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>8.617100</td>\n",
       "      <td>8.608245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>8.637000</td>\n",
       "      <td>8.427113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>8.631900</td>\n",
       "      <td>8.510557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>8.580300</td>\n",
       "      <td>8.441566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>8.563900</td>\n",
       "      <td>8.453546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.574100</td>\n",
       "      <td>8.366509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>8.527900</td>\n",
       "      <td>8.518157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>8.531800</td>\n",
       "      <td>8.405278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>8.487600</td>\n",
       "      <td>8.361155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>8.521300</td>\n",
       "      <td>8.305776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>8.468800</td>\n",
       "      <td>8.373627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>8.470500</td>\n",
       "      <td>8.420248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>8.455000</td>\n",
       "      <td>8.219448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>8.428300</td>\n",
       "      <td>8.367229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>8.452700</td>\n",
       "      <td>8.347764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>8.448800</td>\n",
       "      <td>8.213326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>8.478000</td>\n",
       "      <td>8.177825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>8.454300</td>\n",
       "      <td>8.281873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>8.459000</td>\n",
       "      <td>8.390621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>8.467900</td>\n",
       "      <td>8.416553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>8.407200</td>\n",
       "      <td>8.339363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>8.373600</td>\n",
       "      <td>8.287086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>8.379900</td>\n",
       "      <td>8.232206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>8.388700</td>\n",
       "      <td>8.238578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>8.366200</td>\n",
       "      <td>8.103189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>8.353800</td>\n",
       "      <td>8.201151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>8.349100</td>\n",
       "      <td>8.203523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>8.355000</td>\n",
       "      <td>8.231941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>8.381000</td>\n",
       "      <td>8.214046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>8.376100</td>\n",
       "      <td>8.097723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>8.310600</td>\n",
       "      <td>8.212900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>8.296100</td>\n",
       "      <td>8.109522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>8.266400</td>\n",
       "      <td>8.204401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>8.338000</td>\n",
       "      <td>8.075732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>8.313500</td>\n",
       "      <td>8.220948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>8.328300</td>\n",
       "      <td>8.056803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>8.268000</td>\n",
       "      <td>8.108474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>8.306500</td>\n",
       "      <td>8.050469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>8.281200</td>\n",
       "      <td>7.984207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>8.257900</td>\n",
       "      <td>7.930099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>8.262000</td>\n",
       "      <td>7.853549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>8.241400</td>\n",
       "      <td>7.912779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>8.219000</td>\n",
       "      <td>8.053595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>8.199300</td>\n",
       "      <td>7.950341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>8.208900</td>\n",
       "      <td>7.862159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>8.262600</td>\n",
       "      <td>7.974393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>8.180100</td>\n",
       "      <td>7.950816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>8.269000</td>\n",
       "      <td>8.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>8.157400</td>\n",
       "      <td>7.988266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>8.165200</td>\n",
       "      <td>8.074214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>8.173800</td>\n",
       "      <td>8.009265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>8.162000</td>\n",
       "      <td>8.047486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>8.169100</td>\n",
       "      <td>8.022649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>8.199700</td>\n",
       "      <td>7.976508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>8.153000</td>\n",
       "      <td>8.046255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-1000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-1000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-2000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-2000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-2000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-3000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-3000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [polished/models/ka_only_no_w2v_bert/trainer/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-4000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-4000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [polished/models/ka_only_no_w2v_bert/trainer/checkpoint-2000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-5000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-5000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [polished/models/ka_only_no_w2v_bert/trainer/checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Bad pipe message: %s [b'buO[\\x9f\\x02\\xb0\\x81h\\xed\\x98O\\xe8i\\x86W\\x7fW\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]', b\"\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\", b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b\"\\xa9G\\x91 \\x96M>\\xef\\x1d\\xa2\\xc4F\\x82ORm\\x82\\xe9\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x00\", b'\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/']\n",
      "Bad pipe message: %s [b'q\\xbf\\xe9\\x8aJk\\x082\\x1f\\x02\\xd6~3\\xd2B$\\x92\\x84\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'10D\\xdd\\xd4\\x89\\xbe\\x96\\x0c@]\\x8c\\xd4\\x0e\\xee\\xc7\\xaf\\xdf\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04']\n",
      "Bad pipe message: %s [b'\\x01\\x02']\n",
      "Bad pipe message: %s [b'\\x08dj0\\xe6', b'\\xf0T\\xe2\\xc5(|\\xb2\\xdc:HU\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n']\n",
      "Bad pipe message: %s [b';?\\x0c\\xa0\\x8f\\x17\\x1bs\\x13\\xfc\\xbd\\xe1\\x0f\\x82\\xe4\\x1c%\\x02\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0', b'\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16']\n",
      "Bad pipe message: %s [b\"\\xd9\\x91\\xa9O\\x8bXh\\xc2\\x19\\t`_\\xf3\\xbbN\\xf7\\xb6\\xfb\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\"]\n",
      "Bad pipe message: %s [b\"\\x9c\\xf2\\x96\\x84\\xa8\\x83\\xaf\\xd9aa\\xcb\\x1a\\x9f\\xafTX/`\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\"]\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/trainer/checkpoint-6000\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-6000/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/trainer/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [polished/models/ka_only_no_w2v_bert/trainer/checkpoint-4000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=12,\n",
    "    \n",
    "    #prediction_loss_only=True,\n",
    "    evaluation_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_accumulation_steps=1,\n",
    "    #eval_steps=2000,\n",
    "    logging_first_step=True,\n",
    "    \n",
    "    output_dir= str(out_base/ 'trainer'),\n",
    "    # overwrite_output_dir=True,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6579af3-d39f-4531-99e0-7245b093ffe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to polished/models/ka_only_no_w2v_bert/ka_only_no_w2v_bert_model\n",
      "Configuration saved in polished/models/ka_only_no_w2v_bert/ka_only_no_w2v_bert_model/config.json\n",
      "Model weights saved in polished/models/ka_only_no_w2v_bert/ka_only_no_w2v_bert_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(str(out_base / 'ka_only_no_w2v_bert_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3fc3109-94da-4179-9439-c93ff5c3a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afe0d49e-9cff-4e3f-9f6a-546bcbe8dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert torch.all(model.bert.embeddings.word_embeddings.weight[tokenizer.get_vocab()['ა']] == torch.tensor(wvmodel.wv['ა']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311654b-d757-424e-b99a-ae58ecc7687e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
