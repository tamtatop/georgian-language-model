{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6144c550-4f8a-4ed1-8ee1-2b309a40bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertForMaskedLM\n",
    "from transformers import BertTokenizer\n",
    "import torch.nn\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import RepetitionPenaltyLogitsProcessor\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74e9e02-1d2b-442f-b6d2-e18120dd7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO GET ~6HR TRAINED V2 MODEL WITH W2V EMBEDDINGS\n",
    "MODEL = './polished/models/v2bert/bert_model/'\n",
    "TOKENIZER = './polished/models/v2bert/berttokenizer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94b5dcb-9ba8-4749-91eb-2ec5a21d7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO GET ~2HR TRAINED V2 MODEL WITHOUT W2V EMBEDDINGS\n",
    "MODEL = './polished/models/ka_only_no_w2v_bert/ka_only_no_w2v_bert_model//'\n",
    "TOKENIZER = './polished/models/v2bert/berttokenizer/' # tokenizer same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d42a374-7aa0-4b47-8780-fac9d9c29c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL\n",
    "# RUN THIS TO GET 10HR TRAINED V1 MODEL\n",
    "MODEL = './polished/models/bert/model/'\n",
    "TOKENIZER = './polished/models/bert/berttokenizer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4204f0bc-768c-4fc9-9815-de388dcf7e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./polished/models/bert/model/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(MODEL)\n",
    "tokenizer = BertTokenizer.from_pretrained (TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e169b9-b235-4446-8308-16f5322797db",
   "metadata": {},
   "outputs": [],
   "source": [
    "repetition_penalty=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "314ab6be-8a5f-41b7-8804-ca568c59265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_next_token_softmax(token_ids: list[int]): # we are inferring next token. last token should not be [SEP]\n",
    "    assert token_ids[-1] != tokenizer.sep_token_id\n",
    "    i = len(token_ids)\n",
    "    token_ids = token_ids + [tokenizer.mask_token_id] # + [tokenizer.pad_token_id]*(50-len(token_ids)-10) + [tokenizer.sep_token_id] + [tokenizer.sep_token_id]\n",
    "    token_ids = torch.tensor(token_ids).view((1, -1))\n",
    "    #attention_mask = (token_ids != tokenizer.pad_token_id)*1\n",
    "    #print(attention_mask)\n",
    "    next_token_scores = model(input_ids=token_ids).logits[0, i, :] \n",
    "    logits = F.softmax(next_token_scores, dim=0)\n",
    "    #print(logits.shape)\n",
    "    if repetition_penalty:\n",
    "        logits = RepetitionPenaltyLogitsProcessor(10.0)(token_ids.view(1, -1), logits.view(1, -1))\n",
    "    return logits.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d24b8fe-f588-481c-821b-07d30b188d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_top_k(token_ids: list[int], k: int):\n",
    "    probs = infer_next_token_softmax(token_ids)\n",
    "    tops = list(reversed(sorted([(float(v), i) for i, v in enumerate(probs)])))[:k]\n",
    "    return [(p, i) for p, i in tops] # p, token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c8ef8d-754e-4d91-9d30-bbed5413eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(sentence: str, num_tokens: int, k: int = 5):\n",
    "    assert num_tokens >= 1\n",
    "    token_ids = tokenizer(sentence)['input_ids'][:-1]\n",
    "    cur = [(1.0, [])]\n",
    "    for _ in range(num_tokens):\n",
    "        nexts = []\n",
    "        for p, i in cur:\n",
    "            nexts += [(c_p*p, i+[j]) for c_p, j in get_next_top_k(token_ids + i, k)]\n",
    "        cur = list(reversed(sorted(nexts)))[:k]\n",
    "    return ([tokenizer.decode(token_ids[1:]+toks) for _, toks in cur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ad00f43-719c-441b-adc3-9e03ddafcda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 + 1 = 2', '1 + 1 = /', '1 + 1 = 3', '1 + 1 = 4', '1 + 1 = 1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search('1+1=', 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfe95a72-13ac-4ad6-9c6f-8ad5a6cb93cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 + 1 = 2 - 3',\n",
       " '1 + 1 = 2, 4',\n",
       " '1 + 1 = 2, 3',\n",
       " '1 + 1 = 3, 2',\n",
       " '1 + 1 = 2 - 4']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search('1+1=', 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3a38a5-0e4d-46a9-b97e-86e3b51ef315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['პრეზიდენტი მიხეილ ივანიშვილის',\n",
       " 'პრეზიდენტი მიხეილ ბიძინა',\n",
       " 'პრეზიდენტი მიხეილ ზურაბიშვილი',\n",
       " 'პრეზიდენტი მიხეილ სააკაშვილის',\n",
       " 'პრეზიდენტი მიხეილ სააკაშვილი']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search('პრეზიდენტი მიხეილ', 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4ec7544-c853-4bed-b4d7-fb3da3dc93af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['პრეზიდენტი მიხეილ სააკაშვილი',\n",
       " 'პრეზიდენტი მიხეილ სააკაშვილის',\n",
       " 'პრეზიდენტი მიხეილ სააკაძე',\n",
       " 'პრეზიდენტი მიხეილ სააკაძის',\n",
       " 'პრეზიდენტი მიხეილ სააკიძის']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search('პრეზიდენტი მიხეილ სააკ', 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "726e7a26-939b-4a6b-bd43-1ae6d8e52a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე,',\n",
       " 'პრეზიდენტი მიხეილ სააკაშვილი, რომ განაცხადა -',\n",
       " 'პრეზიდენტი მიხეილ სააკაშვილი, რომ აღნიშნა -',\n",
       " 'პრეზიდენტი მიხეილ სააკაშვილი, რომ ამბობს,',\n",
       " 'პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე -']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search('პრეზიდენტი მიხეილ', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7013574-c2b6-48f8-bf30-3703957d399d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['დღეს მე ვერტმფრენით გავფრინდი და აი, შენ არ ვიცი, რა არის ეს',\n",
       " 'დღეს მე ვერტმფრენით გავფრინდი და აი, შენ არ ვიცი, რომ იმიტომ რომ',\n",
       " 'დღეს მე ვერტმფრენით გავფრინდი და აი, შენ არ ვიცი, რომ იმიტომ,',\n",
       " 'დღეს მე ვერტმფრენით გავფრინდი და აი, შენ არ ვიცი რა უნდა რომ ასე',\n",
       " 'დღეს მე ვერტმფრენით გავფრინდი და აი, შენ არ ვიცი, რომ ასე ვარ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search('დღეს მე ვერტმფრენით გავფრინდი', num_tokens = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a287ce0-ae70-4d19-b743-8ac8e6f0ac46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე, პრემიერ - მინისტრის საგარეო საქმეთა',\n",
       " 'პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე, პრემიერ - მინისტრმა საგარეო საქმეთა',\n",
       " 'პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე, პრემიერ - მინისტრის შინაგან საქმეთა',\n",
       " 'პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე, პრემიერ - მინისტრი საგარეო საქმეთა',\n",
       " 'პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე, პრემიერ - მინისტრის საქმეთა საგარეო']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search('პრეზიდენტი მიხეილ', num_tokens = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e6c7c-0d23-4009-821d-81c83349dc9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Below is MLM demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb07241-c582-4b6b-a5b3-4c163e64878f",
   "metadata": {},
   "source": [
    "### Masked Language Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0148e588-c4b7-4b03-8a0a-3d224d7dba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "773138a2-b9d4-4e84-bcd1-5c878edfd805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./polished/models/v2bert/bert_model/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "fill = pipeline('fill-mask', model=MODEL, tokenizer=TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "eab4ca76-745d-41b6-b628-986044006cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.15355493128299713,\n",
       "  'token': 5,\n",
       "  'token_str': '!',\n",
       "  'sequence': 'პრეზიდენტი მიხეილ! აზრით ამ შენობის აშენება კარგი იდეაა.'},\n",
       " {'score': 0.08936669677495956,\n",
       "  'token': 720,\n",
       "  'token_str': '##ის',\n",
       "  'sequence': 'პრეზიდენტი მიხეილის აზრით ამ შენობის აშენება კარგი იდეაა.'},\n",
       " {'score': 0.08673388510942459,\n",
       "  'token': 9245,\n",
       "  'token_str': 'საათამდე',\n",
       "  'sequence': 'პრეზიდენტი მიხეილ საათამდე აზრით ამ შენობის აშენება კარგი იდეაა.'},\n",
       " {'score': 0.03182349354028702,\n",
       "  'token': 4499,\n",
       "  'token_str': 'გამყიდველისაგან',\n",
       "  'sequence': 'პრეზიდენტი მიხეილ გამყიდველისაგან აზრით ამ შენობის აშენება კარგი იდეაა.'},\n",
       " {'score': 0.028807684779167175,\n",
       "  'token': 747,\n",
       "  'token_str': '##აც',\n",
       "  'sequence': 'პრეზიდენტი მიხეილაც აზრით ამ შენობის აშენება კარგი იდეაა.'}]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill('პრეზიდენტი მიხეილ [MASK] აზრით ამ შენობის აშენება კარგი იდეაა.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "10675297-bebf-4583-a60a-1e1450cfdf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.280554860830307,\n",
       "  'token': 1916,\n",
       "  'token_str': '##შვილი',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არისშვილი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.12002026289701462,\n",
       "  'token': 4996,\n",
       "  'token_str': 'გურამ',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არის გურამ, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.10072647035121918,\n",
       "  'token': 2435,\n",
       "  'token_str': '##იძე',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არისიძე, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.06962481886148453,\n",
       "  'token': 4238,\n",
       "  'token_str': 'ილია',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არის ილია, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.03749911114573479,\n",
       "  'token': 1683,\n",
       "  'token_str': 'ხან',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არის ხან, ცომში გახვეული ხორცი.'}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill('საქართველოს საუკეთესო კერძი არის [MASK], ცომში გახვეული ხორცი.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "02b24fa9-6e5f-4f8d-8853-01cccd0ed3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14893898367881775,\n",
       "  'token': 1916,\n",
       "  'token_str': '##შვილი',\n",
       "  'sequence': 'საუკეთესოშვილი კერძი არის ხინკალი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.10062244534492493,\n",
       "  'token': 6648,\n",
       "  'token_str': '1924',\n",
       "  'sequence': 'საუკეთესო 1924 კერძი არის ხინკალი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.053386539220809937,\n",
       "  'token': 2435,\n",
       "  'token_str': '##იძე',\n",
       "  'sequence': 'საუკეთესოიძე კერძი არის ხინკალი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.048771098256111145,\n",
       "  'token': 10863,\n",
       "  'token_str': 'მაზრა',\n",
       "  'sequence': 'საუკეთესო მაზრა კერძი არის ხინკალი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.048658207058906555,\n",
       "  'token': 520,\n",
       "  'token_str': '##ს',\n",
       "  'sequence': 'საუკეთესოს კერძი არის ხინკალი, ცომში გახვეული ხორცი.'}]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill('საუკეთესო [MASK] კერძი არის ხინკალი, ცომში გახვეული ხორცი.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpproj",
   "language": "python",
   "name": "nlpproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
