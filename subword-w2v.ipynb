{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1da7cea0-d29a-4bc3-9ba6-33e682aa4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dffa3cdb-8bc0-4823-8183-43e78800734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_base = Path('./polished/models/v2bert/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fdbdf376-b12b-40e6-8af4-56cca3903ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './no_en_data/ka_nse_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4c858a58-2157-4353-b726-4e570f90ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_tokenizer = BertWordPieceTokenizer(str(out_base / 'wordpiece' / 'vocab.txt' ), \n",
    "                                      clean_text=True, handle_chinese_chars=True,\n",
    "                                      strip_accents=True, lowercase=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd02c89-d697-4907-a453-7df06a650220",
   "metadata": {},
   "source": [
    "Remember to remove special tokens during w2v training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1c19b72e-30ea-42c9-a9ba-baaa7a5c8755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6399, 1909, 2096, 3]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_tokenizer.encode('შემომეჭამა').ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1da2493e-7e39-47b8-a5b0-ca368919fa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'შემომეჭამა'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_tokenizer.decode(wb_tokenizer.encode('შემომეჭამა').ids[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92e3a7a4-34cf-452a-a3bb-f9bd75be6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs: int\n",
    "def get_subword_sentences():\n",
    "    for i in range(epochs):\n",
    "        with open(data_file) as f:\n",
    "            for line in f:\n",
    "                yield wb_tokenizer.encode(line).tokens[1:-1]\n",
    "        print(f'epoch #{i} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "217590db-b775-44a3-aa8a-0821596534b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = [sent for sent in get_subword_sentences()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7f2bd650-2b87-45a0-af4b-cfa27c61cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sg=1, \n",
    "                 vector_size=300,  \n",
    "                 workers=12,\n",
    "                 window=12, # subwords need more context\n",
    "                 epochs=1, # epochs are controlled above so we can use effient generator\n",
    "                 seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c1d9da2c-b977-4c75-9cc2-2183e1451037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0 done\n",
      "epoch #0 done\n"
     ]
    }
   ],
   "source": [
    "epochs = 1 # 1 epoch for vocab training\n",
    "model.build_vocab(get_subword_sentences())\n",
    "total_sentences = sum(1 for _ in get_subword_sentences())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "76d7050e-552d-41f7-ace3-27cbe2b905f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747262"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d7424d3-5e86-4246-adb8-a91f3201b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0 done\n",
      "epoch #1 done\n",
      "epoch #2 done\n",
      "epoch #3 done\n",
      "epoch #4 done\n",
      "epoch #5 done\n",
      "epoch #6 done\n",
      "epoch #7 done\n",
      "epoch #8 done\n",
      "epoch #9 done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(134444292, 158616630)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10 # n epoch for vocab training\n",
    "model.train(get_subword_sentences(), \n",
    "            total_examples=total_sentences, \n",
    "            epochs=model.epochs\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7f13e071-4033-48e7-8db6-8b128f5a2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./polished/models/word2vec/subword.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d3424625-6887-4d95-854f-cfcc66d30210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('##იაშვილი', 0.7265536785125732),\n",
       " ('##აძე', 0.7166693210601807),\n",
       " ('##ძე', 0.6936086416244507),\n",
       " ('##იშვილი', 0.690089225769043),\n",
       " ('##აშვილი', 0.6892117857933044),\n",
       " ('##რაშვილი', 0.6885238885879517),\n",
       " ('წიკლაური', 0.6833595037460327),\n",
       " ('##უაშვილი', 0.6818857192993164),\n",
       " ('##უნაშვილი', 0.680444061756134),\n",
       " ('##ლიშვილი', 0.6801262497901917)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('##შვილი')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a38bd711-faab-4ef5-96e0-10e980931db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('##ებიც', 0.6364842653274536),\n",
       " ('##ების', 0.49715572595596313),\n",
       " ('##ებისთვის', 0.48254188895225525),\n",
       " ('##ებისგან', 0.46793222427368164),\n",
       " ('##ურები', 0.42871180176734924),\n",
       " ('##ერები', 0.41608086228370667),\n",
       " ('##ებია', 0.4138261675834656),\n",
       " ('##კები', 0.41119346022605896),\n",
       " ('##ეები', 0.4096052944660187),\n",
       " ('ღირ', 0.4076472520828247)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('##ები')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4bea928d-9416-456c-8ecc-d772e9208b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ძროხ', 0.8630732893943787),\n",
       " ('##ატარე', 0.8326977491378784),\n",
       " ('##ყრილი', 0.8293331861495972),\n",
       " ('ძაფ', 0.8266956210136414),\n",
       " ('მღვ', 0.8252092599868774),\n",
       " ('ქუდ', 0.8243218660354614),\n",
       " ('ღილ', 0.8230547308921814),\n",
       " ('გადაქ', 0.8226965069770813),\n",
       " ('##ალაგ', 0.8214482665061951),\n",
       " ('ლოყ', 0.819601833820343)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('ღორ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8cc39-4f1a-4c81-95d4-efa19c658177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
