{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6144c550-4f8a-4ed1-8ee1-2b309a40bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertForMaskedLM\n",
    "from transformers import BertTokenizer\n",
    "import torch.nn\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import RepetitionPenaltyLogitsProcessor\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e74e9e02-1d2b-442f-b6d2-e18120dd7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO GET ~6HR TRAINED V2 MODEL WITH W2V EMBEDDINGS\n",
    "MODEL = './polished/models/v2bert/bert_model/'\n",
    "TOKENIZER = './polished/models/v2bert/berttokenizer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a94b5dcb-9ba8-4749-91eb-2ec5a21d7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO GET ~2HR TRAINED V2 MODEL WITHOUT W2V EMBEDDINGS\n",
    "MODEL = './polished/models/ka_only_no_w2v_bert/ka_only_no_w2v_bert_model//'\n",
    "TOKENIZER = './polished/models/v2bert/berttokenizer/' # tokenizer same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d42a374-7aa0-4b47-8780-fac9d9c29c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO GET 10HR TRAINED V1 MODEL\n",
    "MODEL = './polished/models/bert/model/'\n",
    "TOKENIZER = './polished/models/bert/berttokenizer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4204f0bc-768c-4fc9-9815-de388dcf7e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./polished/models/bert/model/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(MODEL)\n",
    "tokenizer = BertTokenizer.from_pretrained (TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3360dc48-9c02-48ff-b188-756e8a9659c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 1437, 13146, 3], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('რა მაგარია')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47e169b9-b235-4446-8308-16f5322797db",
   "metadata": {},
   "outputs": [],
   "source": [
    "repetition_penalty=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "314ab6be-8a5f-41b7-8804-ca568c59265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_next_token_softmax(token_ids: list[int]): # we are inferring next token. last token should not be [SEP]\n",
    "    assert token_ids[-1] != tokenizer.sep_token_id\n",
    "    i = len(token_ids)\n",
    "    token_ids = token_ids + [tokenizer.mask_token_id] # + [tokenizer.pad_token_id]*(50-len(token_ids)-10) + [tokenizer.sep_token_id] + [tokenizer.sep_token_id]\n",
    "    token_ids = torch.tensor(token_ids).view((1, -1))\n",
    "    #attention_mask = (token_ids != tokenizer.pad_token_id)*1\n",
    "    #print(attention_mask)\n",
    "    next_token_scores = model(input_ids=token_ids).logits[0, i, :] \n",
    "    logits = F.softmax(next_token_scores, dim=0)\n",
    "    #print(logits.shape)\n",
    "    if repetition_penalty:\n",
    "        logits = RepetitionPenaltyLogitsProcessor(10.0)(token_ids.view(1, -1), logits.view(1, -1))\n",
    "    return logits.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa7b1b4-2fcb-4828-9cac-e7324da36247",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = infer_next_token_softmax(tokenizer('რა მაგარია')['input_ids'][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76678dd1-e23b-40c3-8c40-1e6fe90bc68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6969e-12, 4.7368e-06, 7.0409e-07,  ..., 5.2675e-07, 5.0642e-07,\n",
       "        5.2823e-07], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "954bf744-90c9-4364-9c0a-a94e154ae0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity(sentence: str):\n",
    "    token_ids = tokenizer(sentence)['input_ids']\n",
    "    perp = 1\n",
    "    for i in range(1, len(token_ids) - 1):\n",
    "        cur_context = token_ids[:i]\n",
    "        expected_token = token_ids[i]\n",
    "        perp = perp + torch.log(infer_next_token_softmax(cur_context)[expected_token])\n",
    "    return float(torch.exp(-perp/(len(token_ids)-2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b60516e-b0ad-4c4a-aea5-93c1e4f23219",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = []\n",
    "for line in open('./no_en_data/ka_nse_test.txt').readlines()[:200]:\n",
    "    if len(line.strip()) < 5:\n",
    "        continue\n",
    "    perplexities.append((get_perplexity(line), line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29298751-4cbc-4e5c-bdc0-8e40ba4b3fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg perplexity = 2886.7350207955496\n"
     ]
    }
   ],
   "source": [
    "print(f'avg perplexity = {sum([p for p, _ in perplexities])/len(perplexities)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d17a5879-9ea3-4882-bf6d-08efd5ac15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = sorted(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b009305f-3c69-4d7a-871c-4ea84439cec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(84.50183868408203, 'შენ… – დიახ, მე ეს ვიცი!\\n'),\n",
       " (223.10389709472656, 'ეს შესაძლებელი იყო.\\n'),\n",
       " (226.61878967285156, 'მართლა ახალგაზრდა და ლამაზი იყო.\\n'),\n",
       " (264.1933288574219, '-მაშ, როდის შეიძლება შევხვდეთ ერთმანეთს?\\n'),\n",
       " (274.5380554199219, 'არა, ყინული არ მინდა.\\n'),\n",
       " (368.1506042480469, 'შემეძლო ისევ შემყვარებოდა.\\n'),\n",
       " (450.12408447265625,\n",
       "  '-ისიც, ვინც მე მიყვარდა,ხშირად მიემგზავრებოდა ხოლმე.\\n'),\n",
       " (462.02880859375,\n",
       "  'მაგრამ შენ არ გახსოვს, ვერც კი ხვდები ამას, ჩემო საყვარელო!\\n'),\n",
       " (473.8302307128906, '“თანახმა ვარ,\" ვთქვი მე, “ წავიდეთ\".\\n'),\n",
       " (486.3359680175781, 'მივხვდი, სადაც მოვხვდი.\\n')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top perplexities\n",
    "perplexities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2d2d1a2-b59c-4d8a-8938-8948410c5eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7869.26025390625,\n",
       "  'ორმოცი საათის განმავლობაში ვიჯექი მის ლოგინთან, სანამ საბრალო ბავშვის სხეულს გრიპისაგან ცხელების ალმური ასდიოდა.\\n'),\n",
       " (7888.2626953125, 'დღეს \"აღიარებას“ ვარქმევ ამას.\\n'),\n",
       " (7888.2626953125, 'დღეს \"აღიარებას“ ვარქმევ ამას.\\n'),\n",
       " (8620.7041015625, 'დღეს \"მოწიფულობა“ დავარქვი ამას.\\n'),\n",
       " (8620.7041015625, 'დღეს \"მოწიფულობა“ დავარქვი ამას.\\n'),\n",
       " (9148.73828125,\n",
       "  'გასეირნების შემდეგ მე და ჩემი ამხანაგი გოგონა სადარბაზო კართან ვიდექით და ვლაპარაკობდით.\\n'),\n",
       " (10736.5009765625, 'განთიადს ხელი ვტაცე.\\n'),\n",
       " (12525.2041015625,\n",
       "  'გამომშვიდობებისას კვლავ მაჩუქე რამდენიმე ვარდი-გამომშვიდობებისას!\\n'),\n",
       " (14408.65625, '“ჯორჯი რუთს მკერდზე კოცნიდა.\\n'),\n",
       " (22344.73828125, 'ღვინო უმისოდაც მშვენიერია\".\\n')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bad perplexities\n",
    "perplexities[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "119478d5-9e35-4d25-8542-a975bbcbcb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602.6224365234375"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_perplexity('ჩემი აზრით ეს არის ძალიან კარგი იდეა')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7ee0be5c-8425-4a68-b957-01625a8b3a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582.3827514648438"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_perplexity('ჩემი ძალიან ეს არის აზრით იდეა კარგი')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "75621014-1b13-40e5-a74f-353ef796026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "829.9646606445312"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_perplexity('ჩემი ჩემი ჩემი ჩემი ჩემი ჩემი ჩემი')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2638f322-7aa6-4872-81d6-5702f2826cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "641.9747924804688"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_perplexity('ჩემი და რომ მაშინ რადგან რისთვის იმიტომ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d24b8fe-f588-481c-821b-07d30b188d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_top_k(token_ids: list[int], k: int):\n",
    "    probs = infer_next_token_softmax(token_ids)\n",
    "    tops = list(reversed(sorted([(float(v), i) for i, v in enumerate(probs)])))[:k]\n",
    "    return [(p, i) for p, i in tops] # p, token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3c8ef8d-754e-4d91-9d30-bbed5413eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(sentence: str, num_tokens: int, k: int):\n",
    "    assert num_tokens >= 1\n",
    "    token_ids = tokenizer(sentence)['input_ids'][:-1]\n",
    "    cur = [(1.0, [])]\n",
    "    for _ in range(num_tokens):\n",
    "        nexts = []\n",
    "        for p, i in cur:\n",
    "            nexts += [(c_p*p, i+[j]) for c_p, j in get_next_top_k(token_ids + i, k)]\n",
    "        cur = list(reversed(sorted(nexts)))[:k]\n",
    "    print([tokenizer.decode(token_ids[1:]+toks) for _, toks in cur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3616191f-7aa3-487f-b887-025dc5216457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.022892849519848824, 7810),\n",
       " (0.017092948779463768, 5881),\n",
       " (0.01578742265701294, 11108),\n",
       " (0.013783823698759079, 5596),\n",
       " (0.012934033758938313, 6519),\n",
       " (0.009565254673361778, 5129),\n",
       " (0.009293988347053528, 13018),\n",
       " (0.009212212637066841, 2386),\n",
       " (0.008399723097682, 5837),\n",
       " (0.007713967934250832, 4153),\n",
       " (0.007616074755787849, 8524),\n",
       " (0.007227797992527485, 16),\n",
       " (0.006876859813928604, 2867),\n",
       " (0.006577273830771446, 5347),\n",
       " (0.006285976618528366, 2236),\n",
       " (0.005495554301887751, 4073),\n",
       " (0.0054209004156291485, 17),\n",
       " (0.005163147114217281, 6097),\n",
       " (0.005150674842298031, 5918),\n",
       " (0.004721011035144329, 4680)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_top_k(tokenizer('პრეზიდენტი მიხეილ')['input_ids'][:-1], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b795620-5dab-419e-98c2-26e9054a7ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'მმართ'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_tokens[6648]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ad00f43-719c-441b-adc3-9e03ddafcda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 + 1 = 2', '1 + 1 = /', '1 + 1 = 3', '1 + 1 = 4', '1 + 1 = 1']\n"
     ]
    }
   ],
   "source": [
    "beam_search('1+1=', 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfe95a72-13ac-4ad6-9c6f-8ad5a6cb93cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 + 1 = 2 - 3', '1 + 1 = 2, 4', '1 + 1 = 2, 3', '1 + 1 = 3, 2', '1 + 1 = 2 - 4']\n"
     ]
    }
   ],
   "source": [
    "beam_search('1+1=', 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c3a38a5-0e4d-46a9-b97e-86e3b51ef315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['პრეზიდენტი მიხეილ ივანიშვილის', 'პრეზიდენტი მიხეილ ბიძინა', 'პრეზიდენტი მიხეილ ზურაბიშვილი', 'პრეზიდენტი მიხეილ სააკაშვილის', 'პრეზიდენტი მიხეილ სააკაშვილი']\n"
     ]
    }
   ],
   "source": [
    "beam_search('პრეზიდენტი მიხეილ', 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4ec7544-c853-4bed-b4d7-fb3da3dc93af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['პრეზიდენტი მიხეილ სააკაშვილი', 'პრეზიდენტი მიხეილ სააკაშვილის', 'პრეზიდენტი მიხეილ სააკაძე', 'პრეზიდენტი მიხეილ სააკაძის', 'პრეზიდენტი მიხეილ სააკიძის']\n"
     ]
    }
   ],
   "source": [
    "beam_search('პრეზიდენტი მიხეილ სააკ', 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "726e7a26-939b-4a6b-bd43-1ae6d8e52a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე,', 'პრეზიდენტი მიხეილ სააკაშვილი, რომ განაცხადა -', 'პრეზიდენტი მიხეილ სააკაშვილი, რომ აღნიშნა -', 'პრეზიდენტი მიხეილ სააკაშვილი, რომ ამბობს,', 'პრეზიდენტი მიხეილ ზურაბიშვილი : გიორგი ვაშაძე -']\n"
     ]
    }
   ],
   "source": [
    "beam_search('პრეზიდენტი მიხეილ', 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb07241-c582-4b6b-a5b3-4c163e64878f",
   "metadata": {},
   "source": [
    "### Masked Language Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0148e588-c4b7-4b03-8a0a-3d224d7dba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "773138a2-b9d4-4e84-bcd1-5c878edfd805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./polished/models/v2bert/bert_model/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "fill = pipeline('fill-mask', model=MODEL, tokenizer=TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "eab4ca76-745d-41b6-b628-986044006cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.15355493128299713,\n",
       "  'token': 5,\n",
       "  'token_str': '!',\n",
       "  'sequence': 'პრეზიდენტი მიხეილ! აზრით ამ შენობის აშენება კარგი იდეაა.'},\n",
       " {'score': 0.08936669677495956,\n",
       "  'token': 720,\n",
       "  'token_str': '##ის',\n",
       "  'sequence': 'პრეზიდენტი მიხეილის აზრით ამ შენობის აშენება კარგი იდეაა.'},\n",
       " {'score': 0.08673388510942459,\n",
       "  'token': 9245,\n",
       "  'token_str': 'საათამდე',\n",
       "  'sequence': 'პრეზიდენტი მიხეილ საათამდე აზრით ამ შენობის აშენება კარგი იდეაა.'},\n",
       " {'score': 0.03182349354028702,\n",
       "  'token': 4499,\n",
       "  'token_str': 'გამყიდველისაგან',\n",
       "  'sequence': 'პრეზიდენტი მიხეილ გამყიდველისაგან აზრით ამ შენობის აშენება კარგი იდეაა.'},\n",
       " {'score': 0.028807684779167175,\n",
       "  'token': 747,\n",
       "  'token_str': '##აც',\n",
       "  'sequence': 'პრეზიდენტი მიხეილაც აზრით ამ შენობის აშენება კარგი იდეაა.'}]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill('პრეზიდენტი მიხეილ [MASK] აზრით ამ შენობის აშენება კარგი იდეაა.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "10675297-bebf-4583-a60a-1e1450cfdf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.280554860830307,\n",
       "  'token': 1916,\n",
       "  'token_str': '##შვილი',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არისშვილი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.12002026289701462,\n",
       "  'token': 4996,\n",
       "  'token_str': 'გურამ',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არის გურამ, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.10072647035121918,\n",
       "  'token': 2435,\n",
       "  'token_str': '##იძე',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არისიძე, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.06962481886148453,\n",
       "  'token': 4238,\n",
       "  'token_str': 'ილია',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არის ილია, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.03749911114573479,\n",
       "  'token': 1683,\n",
       "  'token_str': 'ხან',\n",
       "  'sequence': 'საქართველოს საუკეთესო კერძი არის ხან, ცომში გახვეული ხორცი.'}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill('საქართველოს საუკეთესო კერძი არის [MASK], ცომში გახვეული ხორცი.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "02b24fa9-6e5f-4f8d-8853-01cccd0ed3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14893898367881775,\n",
       "  'token': 1916,\n",
       "  'token_str': '##შვილი',\n",
       "  'sequence': 'საუკეთესოშვილი კერძი არის ხინკალი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.10062244534492493,\n",
       "  'token': 6648,\n",
       "  'token_str': '1924',\n",
       "  'sequence': 'საუკეთესო 1924 კერძი არის ხინკალი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.053386539220809937,\n",
       "  'token': 2435,\n",
       "  'token_str': '##იძე',\n",
       "  'sequence': 'საუკეთესოიძე კერძი არის ხინკალი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.048771098256111145,\n",
       "  'token': 10863,\n",
       "  'token_str': 'მაზრა',\n",
       "  'sequence': 'საუკეთესო მაზრა კერძი არის ხინკალი, ცომში გახვეული ხორცი.'},\n",
       " {'score': 0.048658207058906555,\n",
       "  'token': 520,\n",
       "  'token_str': '##ს',\n",
       "  'sequence': 'საუკეთესოს კერძი არის ხინკალი, ცომში გახვეული ხორცი.'}]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill('საუკეთესო [MASK] კერძი არის ხინკალი, ცომში გახვეული ხორცი.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpproj",
   "language": "python",
   "name": "nlpproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
